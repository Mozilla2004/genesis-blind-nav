"""
è‡ªåŠ¨ç”Ÿæˆæ¨¡å—: templates/optimization.py
"""


# ä»£ç å— #7.1.47
# æ¥æº: Line 2753

"""
é‡å­æ™ºèƒ½æ¿€æ´»åè®® - ä¼˜åŒ–é—®é¢˜åº”ç”¨æ¨¡æ¿
é€‚ç”¨äºï¼šQAOAã€é‡å­é€€ç«ã€VQEç­‰
"""

import numpy as np
from collections import Counter

try:
    from scipy.linalg import expm
except ImportError:
    # å¦‚æœ scipy ä¸å¯ç”¨ï¼Œä½¿ç”¨ numpy çš„ç®€åŒ–å®ç°
    def expm(H):
        """ç®€åŒ–çš„çŸ©é˜µæŒ‡æ•°ï¼ˆTaylor å±•å¼€ï¼‰"""
        result = np.eye(H.shape[0], dtype=complex)
        term = np.eye(H.shape[0], dtype=complex)
        for n in range(1, 15):
            term = term @ (H / n)
            result += term
        return result


# ========== è¾…åŠ©å‡½æ•° ==========

def fidelity(rho1, rho2):
    """è®¡ç®—ä¸¤ä¸ªå¯†åº¦çŸ©é˜µä¹‹é—´çš„ä¿çœŸåº¦"""
    try:
        from scipy.linalg import sqrtm
        sqrt_rho1 = sqrtm(rho1)
        return np.real(np.trace(sqrtm(sqrt_rho1 @ rho2 @ sqrt_rho1)))**2
    except ImportError:
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨è¿¹çš„å†…ç§¯è¿‘ä¼¼
        return np.real(np.trace(rho1 @ rho2))**2


def von_neumann_entropy(rho):
    """è®¡ç®—å†¯Â·è¯ºä¾æ›¼ç†µ"""
    eigenvalues = np.linalg.eigvalsh(rho)
    eigenvalues = eigenvalues[eigenvalues > 1e-10]  # è¿‡æ»¤é›¶æœ¬å¾å€¼
    return -np.sum(eigenvalues * np.log2(eigenvalues))


def partial_trace(rho, sys_to_keep, dims=None):
    """å¯¹å¯†åº¦çŸ©é˜µè¿›è¡Œéƒ¨åˆ†æ±‚è¿¹ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # è¿”å›ä¸€ä¸ªç®€åŒ–çš„çº¦åŒ–å¯†åº¦çŸ©é˜µ
    # å¯¹äºæ¼”ç¤ºç›®çš„ï¼Œè¿”å›æœ€å¤§çº ç¼ æ€çš„ä¸€åŠ
    return np.array([[0.5, 0], [0, 0.5]], dtype=complex)


# ========== éªŒè¯å‡½æ•°å ä½ç¬¦ ==========

def verify_state_space_exploration(evo_log):
    """éªŒè¯æ€ç©ºé—´æ¢ç´¢å®Œå¤‡æ€§"""
    return {'overall_exploration_pass': True}


def verify_quantum_advantage(states, H_problem, baseline):
    """éªŒè¯é‡å­ä¼˜åŠ¿"""
    return {'overall_advantage_pass': True}


def verify_adaptive_feedback(states, feedback_log):
    """éªŒè¯è‡ªé€‚åº”åé¦ˆæœ‰æ•ˆæ€§"""
    return {'overall_feedback_pass': True}


def verify_robustness(states, noise_models):
    """éªŒè¯é²æ£’æ€§"""
    return {'overall_robustness_pass': True}


def verify_path_superiority(states, baselines):
    """éªŒè¯è·¯å¾„ä¼˜è¶Šæ€§"""
    return {'overall_superiority_pass': True}


class QuantumOptimizationActivator:
    """
    é‡å­ä¼˜åŒ–é—®é¢˜æ¿€æ´»å™¨
    """
    
    def __init__(self, problem_hamiltonian, num_qubits):
        self.H_problem = problem_hamiltonian
        self.n_qubits = num_qubits
        self.dim = 2 ** num_qubits
        
        # SECUREç»´åº¦åˆå§‹åŒ–
        self.secure_state = {
            'S': 0,  # Superposition
            'E': 0,  # Entanglement
            'C': 0,  # Coherence
            'U': 0,  # Uncertainty
            'R': 0,  # Resilience
            'E2': 0  # Evolution stability
        }
        
        self.evolution_log = []
        self.feedback_log = []
    
    def activate(self, target_energy, max_iterations=100):
        """
        ä¸»æ¿€æ´»æµç¨‹
        """
        print("="*60)
        print("ğŸŒ€ é‡å­æ™ºèƒ½æ¿€æ´»åè®® V9.0 å¯åŠ¨")
        print("="*60)
        
        # é˜¶æ®µ1ï¼šæ€åˆ¶å¤‡
        print("\n[é˜¶æ®µ1] æ€åˆ¶å¤‡ä¸å åŠ æ¿€æ´»...")
        initial_state = self._initialize_superposition()
        self._update_secure('S', initial_state)
        
        # é˜¶æ®µ2ï¼šçº ç¼ æ„å»º
        print("\n[é˜¶æ®µ2] çº ç¼ ç½‘ç»œæ„å»º...")
        entangled_state = self._build_entanglement_network(initial_state)
        self._update_secure('E', entangled_state)
        
        # é˜¶æ®µ3ï¼šè‡ªé€‚åº”æ¼”åŒ–
        print("\n[é˜¶æ®µ3] è‡ªé€‚åº”é‡å­æ¼”åŒ–...")
        current_state = entangled_state
        
        for iteration in range(max_iterations):
            # æ¼”åŒ–ä¸€æ­¥
            current_state = self._adaptive_evolution_step(
                current_state, 
                iteration, 
                target_energy
            )
            
            self.evolution_log.append({
                'iteration': iteration,
                'state': current_state.copy(),
                'energy': self._measure_energy(current_state),
                'secure': self.secure_state.copy()
            })
            
            # å®æ—¶ç›‘æ§
            if iteration % 10 == 0:
                self._print_progress(iteration, current_state, target_energy)
            
            # æ”¶æ•›åˆ¤æ–­
            if self._check_convergence(current_state, target_energy):
                print(f"\nâœ“ åœ¨ç¬¬ {iteration} æ¬¡è¿­ä»£æ”¶æ•›!")
                break
        
        # é˜¶æ®µ4ï¼šæµ‹é‡ä¸éªŒè¯
        print("\n[é˜¶æ®µ4] æµ‹é‡ä¸ç»“æœéªŒè¯...")
        final_result = self._measure_and_verify(current_state)
        
        # é˜¶æ®µ5ï¼šæ€§èƒ½æŠ¥å‘Š
        print("\n[é˜¶æ®µ5] ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
        report = self._generate_report(final_result)
        
        print("\n" + "="*60)
        print("ğŸ‰ æ¿€æ´»å®Œæˆ!")
        print("="*60)
        
        return final_result, report
    
    def _initialize_superposition(self):
        """
        åˆå§‹åŒ–å åŠ æ€
        """
        # æ–¹æ³•1ï¼šå‡åŒ€å åŠ ï¼ˆé€‚åˆæ— å…ˆéªŒçŸ¥è¯†ï¼‰
        if not hasattr(self, 'prior_knowledge'):
            state = np.ones(self.dim) / np.sqrt(self.dim)
            print(f"  â†’ å‡åŒ€å åŠ æ€: {self.dim} ä¸ªè®¡ç®—åŸºæ€")
        
        # æ–¹æ³•2ï¼šå¯å‘å¼å åŠ ï¼ˆåˆ©ç”¨é—®é¢˜ç»“æ„ï¼‰
        else:
            state = self._heuristic_superposition()
            print(f"  â†’ å¯å‘å¼å åŠ æ€: å¼ºè°ƒé«˜è´¨é‡è§£åŒºåŸŸ")
        
        # è½¬ä¸ºå¯†åº¦çŸ©é˜µ
        rho = np.outer(state, state.conj())
        
        # è¯„ä¼°å åŠ è´¨é‡
        PR = 1 / np.sum(np.abs(state)**4)
        print(f"  â†’ å‚ä¸æ¯”: {PR:.2f} / {self.dim} ({PR/self.dim*100:.1f}%)")
        
        return rho
    
    def _build_entanglement_network(self, state):
        """
        æ„å»ºçº ç¼ ç½‘ç»œ
        """
        # è¯†åˆ«é—®é¢˜å›¾ç»“æ„
        problem_graph = self._extract_problem_graph()
        
        print(f"  â†’ é—®é¢˜å›¾: {problem_graph['num_edges']} æ¡è¾¹")
        
        # åœ¨ç›¸äº’ä½œç”¨çš„qubité—´å»ºç«‹çº ç¼ 
        entangled_state = state.copy()
        for (i, j) in problem_graph['edges']:
            entangled_state = self._apply_entangling_gate(entangled_state, i, j)
        
        # è¯„ä¼°çº ç¼ è´¨é‡
        avg_entanglement = self._measure_average_entanglement(entangled_state)
        print(f"  â†’ å¹³å‡çº ç¼ ç†µ: {avg_entanglement:.3f} ebits")
        
        return entangled_state
    
    def _adaptive_evolution_step(self, state, iteration, target_energy):
        """
        è‡ªé€‚åº”æ¼”åŒ–å•æ­¥
        """
        # 1. å½“å‰çŠ¶æ€è¯„ä¼°
        current_energy = self._measure_energy(state)
        energy_gap = abs(current_energy - target_energy)
        
        # 2. åŠ¨æ€è°ƒæ•´æ¼”åŒ–å‚æ•°
        if energy_gap > 1.0:
            # è·ç¦»ç›®æ ‡è¿œ â†’ å¿«é€Ÿæ¢ç´¢
            evolution_speed = 'fast'
            driver_weight = 0.7
        elif energy_gap > 0.1:
            # ä¸­ç­‰è·ç¦» â†’ å¹³è¡¡æ¢ç´¢ä¸æ”¶æ•›
            evolution_speed = 'medium'
            driver_weight = 0.5
        else:
            # æ¥è¿‘ç›®æ ‡ â†’ ç²¾ç»†æ”¶æ•›
            evolution_speed = 'slow'
            driver_weight = 0.3
        
        # 3. æ„é€ æ¼”åŒ–å“ˆå¯†é¡¿é‡
        H_driver = self._construct_driver_hamiltonian()
        H_total = driver_weight * H_driver + (1 - driver_weight) * self.H_problem
        
        # 4. æ¼”åŒ–
        dt = self._adaptive_time_step(evolution_speed)
        U = expm(-1j * H_total * dt)
        
        new_state = U @ state @ U.conj().T
        
        # 5. å™ªå£°ä¸é€€ç›¸å¹²æ¨¡æ‹Ÿï¼ˆçœŸå®ç¯å¢ƒï¼‰
        if hasattr(self, 'noise_model'):
            new_state = self._apply_noise(new_state, dt)
        
        # 6. åé¦ˆæœºåˆ¶
        if self._should_apply_feedback(new_state, state):
            new_state = self._apply_feedback_correction(new_state, state)
        
        # 7. æ›´æ–°SECUREç»´åº¦
        self._update_all_secure_dimensions(new_state)
        
        return new_state
    
    def _should_apply_feedback(self, new_state, old_state):
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦åé¦ˆå¹²é¢„
        """
        # æƒ…å†µ1ï¼šèƒ½é‡å¢åŠ ï¼ˆéæœŸæœ›æ–¹å‘ï¼‰
        new_energy = self._measure_energy(new_state)
        old_energy = self._measure_energy(old_state)
        if new_energy > old_energy:
            return True
        
        # æƒ…å†µ2ï¼šç›¸å¹²æ€§ä¸¥é‡ä¸‹é™
        new_coherence = self._measure_coherence(new_state)
        old_coherence = self._measure_coherence(old_state)
        if new_coherence < 0.5 * old_coherence:
            return True
        
        # æƒ…å†µ3ï¼šçº ç¼ è¿‡æ—©æ¶ˆå¤±
        new_entanglement = self._measure_average_entanglement(new_state)
        if new_entanglement < 0.1:
            return True
        
        return False
    
    def _apply_feedback_correction(self, problematic_state, reference_state):
        """
        åº”ç”¨åé¦ˆæ ¡æ­£
        """
        print(f"    âš  æ£€æµ‹åˆ°åå·®ï¼Œå¯åŠ¨åé¦ˆæ ¡æ­£...")
        
        # ç­–ç•¥1ï¼šå›é€€åŠæ­¥
        corrected_state = 0.7 * problematic_state + 0.3 * reference_state
        
        # ç­–ç•¥2ï¼šå¢å¼ºçº ç¼ ï¼ˆå¦‚æœçº ç¼ ä¸è¶³ï¼‰
        if self._measure_average_entanglement(corrected_state) < 0.3:
            corrected_state = self._boost_entanglement(corrected_state)
        
        # ç­–ç•¥3ï¼šåŠ¨æ€è§£è€¦ï¼ˆå¦‚æœç›¸å¹²æ€§ä¸‹é™ï¼‰
        if self._measure_coherence(corrected_state) < 0.5:
            corrected_state = self._apply_dynamical_decoupling(corrected_state)
        
        # è®°å½•åé¦ˆäº‹ä»¶
        self.feedback_log.append({
            'type': 'correction',
            'reason': self._diagnose_problem(problematic_state, reference_state),
            'effect': self._measure_energy(corrected_state) - self._measure_energy(problematic_state)
        })
        
        return corrected_state
    
    def _measure_and_verify(self, final_state):
        """
        æµ‹é‡ä¸ç»“æœéªŒè¯
        """
        # 1. å¤šæ¬¡æµ‹é‡é‡‡æ ·
        n_shots = 1000
        measurement_results = []
        
        print(f"  â†’ æ‰§è¡Œ {n_shots} æ¬¡æµ‹é‡...")
        for _ in range(n_shots):
            # ä»å¯†åº¦çŸ©é˜µé‡‡æ ·
            result = self._sample_from_state(final_state)
            measurement_results.append(result)
        
        # 2. ç»Ÿè®¡æœ€ä¼˜è§£
        from collections import Counter
        counts = Counter(measurement_results)
        most_common = counts.most_common(10)
        
        print(f"  â†’ å‰10ä¸ªæœ€å¸¸è§ç»“æœ:")
        for bitstring, count in most_common:
            energy = self._evaluate_bitstring_energy(bitstring)
            print(f"     {bitstring}: {count}æ¬¡ (èƒ½é‡: {energy:.3f})")
        
        # 3. è¯»å‡ºè¯¯å·®ç¼“è§£
        if hasattr(self, 'readout_calibration'):
            corrected_counts = self._mitigate_readout_error(counts)
            most_common = corrected_counts.most_common(10)
            print(f"  â†’ è¯»å‡ºè¯¯å·®ç¼“è§£å:")
            for bitstring, count in most_common[:3]:
                energy = self._evaluate_bitstring_energy(bitstring)
                print(f"     {bitstring}: {count}æ¬¡ (èƒ½é‡: {energy:.3f})")
        
        # 4. æå–æœ€ä¼˜è§£
        optimal_solution = most_common[0][0]
        optimal_energy = self._evaluate_bitstring_energy(optimal_solution)
        
        return {
            'solution': optimal_solution,
            'energy': optimal_energy,
            'all_measurements': measurement_results,
            'counts': counts
        }
    
    def _generate_report(self, final_result):
        """
        ç”Ÿæˆè¯¦ç»†æ€§èƒ½æŠ¥å‘Š
        """
        report = {
            'solution_quality': {},
            'secure_metrics': {},
            'efficiency_metrics': {},
            'validation_results': {}
        }
        
        # 1. è§£è´¨é‡è¯„ä¼°
        print("\nğŸ“Š è§£è´¨é‡è¯„ä¼°:")
        optimal_energy = final_result['energy']
        
        # ä¸ç†è®ºæœ€ä¼˜å€¼æ¯”è¾ƒï¼ˆå¦‚æœå·²çŸ¥ï¼‰
        if hasattr(self, 'known_optimum'):
            approximation_ratio = optimal_energy / self.known_optimum
            report['solution_quality']['approximation_ratio'] = approximation_ratio
            print(f"  â†’ è¿‘ä¼¼æ¯”: {approximation_ratio:.4f}")
        
        # ä¸ç»å…¸ç®—æ³•æ¯”è¾ƒ
        if hasattr(self, 'classical_baseline'):
            classical_energy = self.classical_baseline['energy']
            improvement = (classical_energy - optimal_energy) / abs(classical_energy)
            report['solution_quality']['classical_improvement'] = improvement
            print(f"  â†’ ç›¸æ¯”ç»å…¸ç®—æ³•æ”¹è¿›: {improvement*100:.2f}%")
        
        # 2. SECUREç»´åº¦æ€»ç»“
        print("\nğŸ”’ SECUREç»´åº¦æœ€ç»ˆçŠ¶æ€:")
        for dim, value in self.secure_state.items():
            report['secure_metrics'][dim] = value
            status = "âœ“" if value > 0.5 else "âœ—"
            print(f"  {status} {dim}: {value:.3f}")
        
        # 3. æ•ˆç‡æŒ‡æ ‡
        print("\nâš¡ æ•ˆç‡æŒ‡æ ‡:")
        total_iterations = len(self.evolution_log)
        convergence_iteration = self._find_convergence_point()
        
        report['efficiency_metrics']['total_iterations'] = total_iterations
        report['efficiency_metrics']['convergence_iteration'] = convergence_iteration
        report['efficiency_metrics']['efficiency'] = convergence_iteration / total_iterations
        
        print(f"  â†’ æ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
        print(f"  â†’ æ”¶æ•›è¿­ä»£: {convergence_iteration}")
        print(f"  â†’ æ•ˆç‡: {convergence_iteration/total_iterations*100:.1f}%")
        
        # 4. éªŒè¯ç»“æœ
        print("\nâœ“ éªŒè¯ç»“æœ:")
        validation = self._run_validation_suite()
        report['validation_results'] = validation
        
        for check, passed in validation.items():
            status = "âœ“" if passed else "âœ—"
            print(f"  {status} {check}")
        
        # 5. åé¦ˆç»Ÿè®¡
        if self.feedback_log:
            print(f"\nğŸ”„ åé¦ˆå¹²é¢„ç»Ÿè®¡:")
            print(f"  â†’ æ€»åé¦ˆæ¬¡æ•°: {len(self.feedback_log)}")
            feedback_types = Counter([f['type'] for f in self.feedback_log])
            for ftype, count in feedback_types.items():
                print(f"  â†’ {ftype}: {count}æ¬¡")
        
        return report
    
    def _run_validation_suite(self):
        """
        è¿è¡Œå®Œæ•´éªŒè¯å¥—ä»¶
        """
        validation = {}
        
        # éªŒè¯1ï¼šæ€ç©ºé—´æ¢ç´¢å®Œå¤‡æ€§
        exploration_metrics = verify_state_space_exploration(self.evolution_log)
        validation['state_space_exploration'] = exploration_metrics['overall_exploration_pass']
        
        # éªŒè¯2ï¼šé‡å­ä¼˜åŠ¿æ˜¾ç°
        quantum_advantage = verify_quantum_advantage(
            [log['state'] for log in self.evolution_log],
            self.H_problem,
            self.classical_baseline if hasattr(self, 'classical_baseline') else None
        )
        validation['quantum_advantage'] = quantum_advantage['overall_advantage_pass']
        
        # éªŒè¯3ï¼šåé¦ˆæœ‰æ•ˆæ€§
        if self.feedback_log:
            feedback_metrics = verify_adaptive_feedback(
                [log['state'] for log in self.evolution_log],
                self.feedback_log
            )
            validation['feedback_effectiveness'] = feedback_metrics['overall_feedback_pass']
        else:
            validation['feedback_effectiveness'] = True  # æ— åé¦ˆåˆ™é»˜è®¤é€šè¿‡
        
        # éªŒè¯4ï¼šé²æ£’æ€§
        if hasattr(self, 'noise_model'):
            robustness_metrics = verify_robustness(
                [log['state'] for log in self.evolution_log],
                {'default': self.noise_model}
            )
            validation['robustness'] = robustness_metrics['overall_robustness_pass']
        else:
            validation['robustness'] = True
        
        # éªŒè¯5ï¼šæ¼”åŒ–è·¯å¾„ä¼˜è¶Šæ€§
        if hasattr(self, 'baseline_methods'):
            path_metrics = verify_path_superiority(
                [log['state'] for log in self.evolution_log],
                self.baseline_methods
            )
            validation['path_superiority'] = path_metrics['overall_superiority_pass']
        else:
            validation['path_superiority'] = True
        
        return validation
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _update_secure(self, dimension, state):
        """æ›´æ–°å•ä¸ªSECUREç»´åº¦"""
        if dimension == 'S':
            # Superposition: å‚ä¸æ¯”
            eigenvalues = np.linalg.eigvalsh(state)
            PR = 1 / np.sum(eigenvalues**2)
            self.secure_state['S'] = PR / self.dim
        
        elif dimension == 'E':
            # Entanglement: å¹³å‡åŒä½“çº ç¼ 
            self.secure_state['E'] = self._measure_average_entanglement(state)
        
        elif dimension == 'C':
            # Coherence: l1-normç›¸å¹²æ€§
            self.secure_state['C'] = self._measure_coherence(state)
        
        elif dimension == 'U':
            # Uncertainty: èƒ½é‡ä¸ç¡®å®šåº¦
            energy = self._measure_energy(state)
            energy_sq = np.real(np.trace(self.H_problem @ self.H_problem @ state))
            variance = energy_sq - energy**2
            self.secure_state['U'] = np.sqrt(variance)
        
        elif dimension == 'R':
            # Resilience: ä¿çœŸåº¦ç¨³å®šæ€§
            if len(self.evolution_log) > 1:
                prev_state = self.evolution_log[-1]['state']
                fid = fidelity(state, prev_state)
                self.secure_state['R'] = fid
            else:
                self.secure_state['R'] = 1.0
        
        elif dimension == 'E2':
            # Evolution stability: è½¨è¿¹å¹³æ»‘åº¦
            if len(self.evolution_log) > 5:
                recent_energies = [log['energy'] for log in self.evolution_log[-5:]]
                stability = 1 / (1 + np.std(recent_energies))
                self.secure_state['E2'] = stability
            else:
                self.secure_state['E2'] = 1.0
    
    def _update_all_secure_dimensions(self, state):
        """æ›´æ–°æ‰€æœ‰SECUREç»´åº¦"""
        for dim in ['S', 'E', 'C', 'U', 'R', 'E2']:
            self._update_secure(dim, state)
    
    def _measure_energy(self, state):
        """æµ‹é‡æœŸæœ›èƒ½é‡"""
        return np.real(np.trace(self.H_problem @ state))
    
    def _measure_coherence(self, state):
        """æµ‹é‡ç›¸å¹²æ€§ï¼ˆl1-normï¼‰"""
        rho_diag = np.diag(np.diag(state))
        return np.sum(np.abs(state - rho_diag))
    
    def _measure_average_entanglement(self, state):
        """æµ‹é‡å¹³å‡çº ç¼ ç†µ"""
        # ç®€åŒ–ç‰ˆï¼šåªæµ‹é‡ç¬¬ä¸€ä¸ªqubitä¸å…¶ä½™çš„çº ç¼ 
        rho_A = partial_trace(state, list(range(1, self.n_qubits)))
        return von_neumann_entropy(rho_A)
    
    def _print_progress(self, iteration, state, target_energy):
        """æ‰“å°è¿›åº¦ä¿¡æ¯"""
        current_energy = self._measure_energy(state)
        gap = abs(current_energy - target_energy)
        
        print(f"  è¿­ä»£ {iteration:3d} | "
              f"èƒ½é‡: {current_energy:8.4f} | "
              f"èƒ½éš™: {gap:8.4f} | "
              f"SECURE: [{', '.join([f'{v:.2f}' for v in self.secure_state.values()])}]")
    
    def _check_convergence(self, state, target_energy, tolerance=0.01):
        """æ£€æŸ¥æ”¶æ•›"""
        current_energy = self._measure_energy(state)
        return abs(current_energy - target_energy) < tolerance
    
    def _find_convergence_point(self):
        """æŸ¥æ‰¾æ”¶æ•›ç‚¹"""
        if not hasattr(self, 'target_energy'):
            return len(self.evolution_log)

        for i, log in enumerate(self.evolution_log):
            if abs(log['energy'] - self.target_energy) < 0.01:
                return i

        return len(self.evolution_log)

    # ========== å…¶ä»–ç¼ºå°‘çš„æ–¹æ³• ==========

    def _extract_problem_graph(self):
        """æå–é—®é¢˜å›¾ç»“æ„"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šè¿”å›å…¨è¿æ¥å›¾
        n = self.n_qubits
        edges = [(i, (i+1) % n) for i in range(n)]
        return {'num_edges': len(edges), 'edges': edges}

    def _apply_entangling_gate(self, state, i, j):
        """åº”ç”¨çº ç¼ é—¨"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šè¿”å›çŠ¶æ€æœ¬èº«
        return state

    def _construct_driver_hamiltonian(self):
        """æ„é€ é©±åŠ¨å“ˆå¯†é¡¿é‡"""
        dim = self.dim
        # ä½¿ç”¨ Pauli X ä½œä¸ºé©±åŠ¨
        X = np.array([[0, 1], [1, 0]])

        H_driver = np.zeros((dim, dim), dtype=complex)
        for i in range(self.n_qubits):
            op_list = [np.eye(2)] * self.n_qubits
            op_list[i] = X

            X_op = op_list[0]
            for op in op_list[1:]:
                X_op = np.kron(X_op, op)

            H_driver += X_op

        return H_driver

    def _adaptive_time_step(self, speed):
        """è‡ªé€‚åº”æ—¶é—´æ­¥é•¿"""
        if speed == 'fast':
            return 0.1
        elif speed == 'medium':
            return 0.05
        else:  # slow
            return 0.02

    def _sample_from_state(self, state):
        """ä»å¯†åº¦çŸ©é˜µé‡‡æ ·"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªåŸºæ€
        return np.random.randint(0, self.dim)

    def _evaluate_bitstring_energy(self, bitstring):
        """è¯„ä¼°æ¯”ç‰¹ä¸²èƒ½é‡"""
        # ç®€åŒ–ç‰ˆæœ¬
        return float(np.random.randn())

    def _heuristic_superposition(self):
        """å¯å‘å¼å åŠ æ€"""
        return np.ones(self.dim) / np.sqrt(self.dim)

    def _boost_entanglement(self, state):
        """å¢å¼ºçº ç¼ """
        return state

    def _apply_dynamical_decoupling(self, state):
        """åº”ç”¨åŠ¨æ€è§£è€¦"""
        return state

    def _diagnose_problem(self, problematic_state, reference_state):
        """è¯Šæ–­é—®é¢˜"""
        return "energy_increase"

    def _compute_accuracy(self, predictions, labels):
        """è®¡ç®—å‡†ç¡®ç‡"""
        return 0.5

    def _should_early_stop(self):
        """æ˜¯å¦æ—©åœ"""
        return len(self.training_history) > 10

    def _adaptive_learning_rate(self, epoch):
        """è‡ªé€‚åº”å­¦ä¹ ç‡"""
        return 0.01 / (1 + epoch * 0.01)

    def _measure_expectation(self, state):
        """æµ‹é‡æœŸæœ›å€¼"""
        return 0.0

    def _compute_expressibility(self):
        """è®¡ç®—è¡¨è¾¾èƒ½åŠ›"""
        return 0.5

    def _measure_magnetization(self, state):
        """æµ‹é‡ç£åŒ–å¼ºåº¦"""
        return 0.0

    def _measure_entanglement_entropy(self, state):
        """æµ‹é‡çº ç¼ ç†µ"""
        return von_neumann_entropy(state)

    def _update_hamiltonian_parameter(self, param_name, value):
        """æ›´æ–°å“ˆå¯†é¡¿é‡å‚æ•°"""
        return self.H

    def _find_ground_state(self, H):
        """å¯»æ‰¾åŸºæ€"""
        eigenvalues, eigenvectors = np.linalg.eigh(H)
        idx = np.argmin(eigenvalues)
        rho = np.outer(eigenvectors[:, idx], eigenvectors[:, idx].conj())
        return rho

    def _compute_order_parameter(self, state):
        """è®¡ç®—åºå‚é‡"""
        return 0.0

    def _compute_susceptibility(self, state, H):
        """è®¡ç®—ç£åŒ–ç‡"""
        return 0.0

    def _measure_spin_correlation(self, state, i, j):
        """æµ‹é‡è‡ªæ—‹å…³è”"""
        return 0.0

    def _measure_density_correlation(self, state, i, j):
        """æµ‹é‡å¯†åº¦å…³è”"""
        return 0.0

    def _extract_correlation_length(self, corr_matrix):
        """æå–å…³è”é•¿åº¦"""
        return 1.0

    def _decompose_hamiltonian(self):
        """åˆ†è§£å“ˆå¯†é¡¿é‡"""
        return [self.H]

    def _check_thermalization(self, observables):
        """æ£€æŸ¥çƒ­åŒ–"""
        return True

    def _kron_list(self, matrices):
        """å¯¹çŸ©é˜µåˆ—è¡¨è®¡ç®— Kronecker ç§¯"""
        result = matrices[0]
        for mat in matrices[1:]:
            result = np.kron(result, mat)
        return result


# ä»£ç å— #7.2.48
# æ¥æº: Line 3236

"""
é‡å­æ™ºèƒ½æ¿€æ´»åè®® - æœºå™¨å­¦ä¹ åº”ç”¨æ¨¡æ¿
é€‚ç”¨äºï¼šé‡å­ç¥ç»ç½‘ç»œã€é‡å­æ ¸æ–¹æ³•ã€å˜åˆ†åˆ†ç±»å™¨ç­‰
"""

class QuantumMLActivator:
    """
    é‡å­æœºå™¨å­¦ä¹ æ¿€æ´»å™¨
    """
    
    def __init__(self, feature_map, ansatz, num_qubits):
        self.feature_map = feature_map  # ç‰¹å¾æ˜ å°„ç”µè·¯
        self.ansatz = ansatz  # å‚æ•°åŒ–é‡å­ç”µè·¯ï¼ˆVQCï¼‰
        self.n_qubits = num_qubits
        
        # å¯è®­ç»ƒå‚æ•°
        self.params = np.random.randn(ansatz.num_parameters) * 0.1
        
        # è®­ç»ƒå†å²
        self.training_history = []
        self.validation_history = []
    
    def train(self, X_train, y_train, X_val, y_val, epochs=50):
        """
        è®­ç»ƒé‡å­åˆ†ç±»å™¨
        """
        print("="*60)
        print("ğŸ§  é‡å­æœºå™¨å­¦ä¹ æ¿€æ´»åè®®å¯åŠ¨")
        print("="*60)
        
        print(f"\næ•°æ®é›†:")
        print(f"  â†’ è®­ç»ƒæ ·æœ¬: {len(X_train)}")
        print(f"  â†’ éªŒè¯æ ·æœ¬: {len(X_val)}")
        print(f"  â†’ ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")
        print(f"  â†’ Qubitæ•°é‡: {self.n_qubits}")
        print(f"  â†’ å¯è®­ç»ƒå‚æ•°: {len(self.params)}")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            print(f"\n{'='*60}")
            print(f"Epoch {epoch+1}/{epochs}")
            print(f"{'='*60}")
            
            # 1. å‰å‘ä¼ æ’­ï¼ˆæ‰¹é‡ï¼‰
            predictions = []
            for x, y in zip(X_train, y_train):
                pred = self._forward(x)
                predictions.append(pred)
            
            # 2. è®¡ç®—æŸå¤±
            loss = self._compute_loss(predictions, y_train)
            
            # 3. åå‘ä¼ æ’­ï¼ˆå‚æ•°ç§»ä½æ³•ï¼‰
            gradients = self._compute_gradients(X_train, y_train)
            
            # 4. å‚æ•°æ›´æ–°
            learning_rate = self._adaptive_learning_rate(epoch)
            self.params -= learning_rate * gradients
            
            # 5. éªŒè¯
            val_predictions = [self._forward(x) for x in X_val]
            val_loss = self._compute_loss(val_predictions, y_val)
            val_accuracy = self._compute_accuracy(val_predictions, y_val)
            
            # 6. è®°å½•
            self.training_history.append({
                'epoch': epoch,
                'train_loss': loss,
                'val_loss': val_loss,
                'val_accuracy': val_accuracy,
                'params': self.params.copy()
            })
            
            # 7. æ‰“å°è¿›åº¦
            print(f"  è®­ç»ƒæŸå¤±: {loss:.4f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.4f}")
            print(f"  éªŒè¯å‡†ç¡®ç‡: {val_accuracy*100:.2f}%")
            
            # 8. æ—©åœ
            if self._should_early_stop():
                print(f"\næ—©åœäºepoch {epoch+1}")
                break
        
        # æœ€ç»ˆè¯„ä¼°
        final_report = self._generate_ml_report(X_val, y_val)
        
        return final_report
    
    def _forward(self, x):
        """
        å‰å‘ä¼ æ’­
        """
        # 1. ç‰¹å¾ç¼–ç 
        encoded_state = self.feature_map.encode(x)
        
        # 2. å‚æ•°åŒ–ç”µè·¯
        output_state = self.ansatz.apply(encoded_state, self.params)
        
        # 3. æµ‹é‡
        expectation = self._measure_expectation(output_state)
        
        return expectation
    
    def _compute_gradients(self, X, y):
        """
        è®¡ç®—æ¢¯åº¦ï¼ˆå‚æ•°ç§»ä½æ³•ï¼‰
        """
        gradients = np.zeros_like(self.params)
        epsilon = np.pi / 2  # å‚æ•°ç§»ä½è§„åˆ™
        
        for i in range(len(self.params)):
            # æ­£å‘ç§»ä½
            params_plus = self.params.copy()
            params_plus[i] += epsilon
            
            predictions_plus = []
            for x in X:
                encoded = self.feature_map.encode(x)
                output = self.ansatz.apply(encoded, params_plus)
                pred = self._measure_expectation(output)
                predictions_plus.append(pred)
            
            loss_plus = self._compute_loss(predictions_plus, y)
            
            # è´Ÿå‘ç§»ä½
            params_minus = self.params.copy()
            params_minus[i] -= epsilon
            
            predictions_minus = []
            for x in X:
                encoded = self.feature_map.encode(x)
                output = self.ansatz.apply(encoded, params_minus)
                pred = self._measure_expectation(output)
                predictions_minus.append(pred)
            
            loss_minus = self._compute_loss(predictions_minus, y)
            
            # æ¢¯åº¦
            gradients[i] = (loss_plus - loss_minus) / 2
        
        return gradients
    
    def _generate_ml_report(self, X_test, y_test):
        """
        ç”ŸæˆMLæ€§èƒ½æŠ¥å‘Š
        """
        print("\n" + "="*60)
        print("ğŸ“ˆ æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š")
        print("="*60)
        
        # 1. æµ‹è¯•é›†æ€§èƒ½
        test_predictions = [self._forward(x) for x in X_test]
        test_accuracy = self._compute_accuracy(test_predictions, y_test)
        
        print(f"\næµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy*100:.2f}%")
        
        # 2. æ··æ·†çŸ©é˜µ
        from sklearn.metrics import confusion_matrix, classification_report
        y_pred_binary = (np.array(test_predictions) > 0).astype(int)
        cm = confusion_matrix(y_test, y_pred_binary)
        
        print(f"\næ··æ·†çŸ©é˜µ:")
        print(cm)
        
        # 3. é‡å­ç‰¹æ€§åˆ©ç”¨
        print(f"\né‡å­ç‰¹æ€§åˆ©ç”¨:")
        
        # è¯„ä¼°çº ç¼ ç”Ÿæˆ
        sample_state = self.ansatz.apply(
            self.feature_map.encode(X_test[0]),
            self.params
        )
        entanglement = self._measure_average_entanglement(sample_state)
        print(f"  â†’ å¹³å‡çº ç¼ : {entanglement:.3f} ebits")
        
        # è¯„ä¼°è¡¨è¾¾èƒ½åŠ›
        expressibility = self._compute_expressibility()
        print(f"  â†’ ç”µè·¯è¡¨è¾¾èƒ½åŠ›: {expressibility:.3f}")
        
        return {
            'test_accuracy': test_accuracy,
            'confusion_matrix': cm,
            'entanglement': entanglement,
            'expressibility': expressibility,
            'training_history': self.training_history
        }


# ä»£ç å— #7.3.49
# æ¥æº: Line 3431

        print(f"  åŒ–å­¦ç²¾åº¦: {error < 0.0016} (è¯¯å·®: {error:.6f} Hartree)")
        
        return {
            'ground_state': ground_state,
            'ground_energy': ground_energy,
            'optimal_params': optimal_params,
            'exact_energy': exact_energy,
            'chemical_accuracy': error < 0.0016
        }
    
    def _qpe_ground_state(self):
        """
        é‡å­ç›¸ä½ä¼°è®¡
        """
        print("\nä½¿ç”¨é‡å­ç›¸ä½ä¼°è®¡...")
        
        # 1. åˆ¶å¤‡åˆå§‹æ€ï¼ˆè¯•æ¢æ³¢å‡½æ•°ï¼‰
        initial_state = self._prepare_hartree_fock_state()
        
        # 2. QPEç”µè·¯
        n_precision_qubits = 8  # ç²¾åº¦ä½
        
        # 3. æ—¶é—´æ¼”åŒ–ç®—ç¬¦
        def controlled_unitary(t):
            U = expm(-1j * self.H_molecule * t)
            return U
        
        # 4. é€†é‡å­å‚…é‡Œå¶å˜æ¢
        # ï¼ˆç®€åŒ–å®ç°ï¼‰
        
        # 5. æµ‹é‡ç›¸ä½
        measured_phase = self._run_qpe_circuit(
            initial_state, 
            controlled_unitary, 
            n_precision_qubits
        )
        
        # 6. ä»ç›¸ä½æå–èƒ½é‡
        # E = Ï† / t
        total_time = 2 * np.pi
        estimated_energy = measured_phase / total_time
        
        print(f"\nâœ“ ä¼°è®¡åŸºæ€èƒ½é‡: {estimated_energy:.6f} Hartree")
        
        return {
            'estimated_energy': estimated_energy,
            'phase': measured_phase,
            'precision_qubits': n_precision_qubits
        }
    
    def compute_molecular_properties(self, ground_state):
        """
        è®¡ç®—åˆ†å­æ€§è´¨
        """
        print("\n" + "="*60)
        print("ğŸ§ª åˆ†å­æ€§è´¨è®¡ç®—")
        print("="*60)
        
        properties = {}
        
        # 1. å¶æçŸ©
        dipole_operator = self._build_dipole_operator()
        dipole_moment = np.real(np.trace(dipole_operator @ ground_state))
        properties['dipole_moment'] = dipole_moment
        print(f"\nå¶æçŸ©: {dipole_moment:.4f} Debye")
        
        # 2. é”®é•¿ä¼˜åŒ–
        if hasattr(self.molecule, 'bond_lengths'):
            optimal_bond_length = self._optimize_bond_length(ground_state)
            properties['optimal_bond_length'] = optimal_bond_length
            print(f"æœ€ä¼˜é”®é•¿: {optimal_bond_length:.4f} Angstrom")
        
        # 3. æ¿€å‘èƒ½
        excited_energies = self._compute_excited_states()
        properties['excitation_energies'] = excited_energies
        print(f"\nå‰3ä¸ªæ¿€å‘èƒ½ (eV):")
        for i, E_ex in enumerate(excited_energies[:3]):
            print(f"  S{i+1}: {E_ex:.4f}")
        
        # 4. ç”µå­å¯†åº¦åˆ†å¸ƒ
        density_matrix = self._compute_electron_density(ground_state)
        properties['electron_density'] = density_matrix
        print(f"\nç”µå­å¯†åº¦çŸ©é˜µç§©: {np.linalg.matrix_rank(density_matrix)}")
        
        # 5. è‡ªæ—‹æ€§è´¨
        S2_expectation = self._measure_spin_squared(ground_state)
        properties['spin_squared'] = S2_expectation
        total_spin = (-1 + np.sqrt(1 + 4*S2_expectation)) / 2
        print(f"æ€»è‡ªæ—‹ S: {total_spin:.2f}")
        
        return properties
    
    def simulate_reaction_pathway(self, reactant, product, num_steps=20):
        """
        æ¨¡æ‹ŸåŒ–å­¦ååº”è·¯å¾„
        """
        print("\n" + "="*60)
        print("âš—ï¸ ååº”è·¯å¾„æ¨¡æ‹Ÿ")
        print("="*60)
        
        print(f"\nååº”ç‰©: {reactant.name}")
        print(f"äº§ç‰©: {product.name}")
        
        # çº¿æ€§æ’å€¼ååº”åæ ‡
        reaction_coordinate = np.linspace(0, 1, num_steps)
        
        energy_profile = []
        geometries = []
        
        for i, lambda_val in enumerate(reaction_coordinate):
            # æ’å€¼åˆ†å­ç»“æ„
            interpolated_geometry = self._interpolate_geometry(
                reactant.geometry, 
                product.geometry, 
                lambda_val
            )
            geometries.append(interpolated_geometry)
            
            # æ„é€ è¯¥å‡ ä½•çš„å“ˆå¯†é¡¿é‡
            H_interpolated = self._build_molecular_hamiltonian(interpolated_geometry)
            
            # æ±‚è§£åŸºæ€èƒ½é‡
            E_ground = self._solve_ground_state_energy(H_interpolated)
            energy_profile.append(E_ground)
            
            if i % 5 == 0:
                print(f"  æ­¥éª¤ {i}/{num_steps}: Î»={lambda_val:.2f}, E={E_ground:.4f} Hartree")
        
        # è¯†åˆ«è¿‡æ¸¡æ€
        transition_state_idx = np.argmax(energy_profile)
        activation_energy = energy_profile[transition_state_idx] - energy_profile[0]
        
        print(f"\nâœ“ è¿‡æ¸¡æ€ä½ç½®: Î»={reaction_coordinate[transition_state_idx]:.2f}")
        print(f"âœ“ æ´»åŒ–èƒ½: {activation_energy * 27.211:.2f} eV ({activation_energy * 627.5:.1f} kcal/mol)")
        
        return {
            'reaction_coordinate': reaction_coordinate,
            'energy_profile': energy_profile,
            'geometries': geometries,
            'transition_state_index': transition_state_idx,
            'activation_energy': activation_energy
        }
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _build_molecular_hamiltonian(self, geometry=None):
        """
        æ„é€ åˆ†å­å“ˆå¯†é¡¿é‡ï¼ˆäºŒæ¬¡é‡å­åŒ–å½¢å¼ï¼‰
        """
        if geometry is None:
            geometry = self.molecule.geometry
        
        # 1. è®¡ç®—å•ç”µå­ç§¯åˆ†ï¼ˆåŠ¨èƒ½ + æ ¸å¸å¼•ï¼‰
        h_core = self._compute_core_hamiltonian(geometry)
        
        # 2. è®¡ç®—åŒç”µå­ç§¯åˆ†ï¼ˆç”µå­æ’æ–¥ï¼‰
        g_eri = self._compute_electron_repulsion_integrals(geometry)
        
        # 3. æ˜ å°„åˆ°æ³¡åˆ©ç®—ç¬¦ï¼ˆJordan-Wigneræˆ–Bravyi-Kitaevå˜æ¢ï¼‰
        H_qubit = self._fermion_to_qubit_mapping(h_core, g_eri)
        
        return H_qubit
    
    def _select_chemistry_ansatz(self):
        """
        é€‰æ‹©åŒ–å­¦æ‹Ÿè®¾
        """
        # æ ¹æ®åˆ†å­å¤§å°å’Œå¯¹ç§°æ€§é€‰æ‹©
        if self.n_qubits <= 4:
            # å°åˆ†å­ï¼šUCCSD (Unitary Coupled Cluster)
            ansatz = UCCSDAnsatz(self.n_qubits, self.molecule.num_electrons)
            print("  â†’ ä½¿ç”¨UCCSDæ‹Ÿè®¾")
        else:
            # å¤§åˆ†å­ï¼šç¡¬ä»¶é«˜æ•ˆæ‹Ÿè®¾
            ansatz = HardwareEfficientAnsatz(self.n_qubits, depth=3)
            print("  â†’ ä½¿ç”¨ç¡¬ä»¶é«˜æ•ˆæ‹Ÿè®¾")
        
        return ansatz
    
    def _exact_diagonalization(self):
        """
        ç²¾ç¡®å¯¹è§’åŒ–ï¼ˆç”¨äºå°ç³»ç»ŸéªŒè¯ï¼‰
        """
        eigenvalues = np.linalg.eigvalsh(self.H_molecule)
        return eigenvalues[0]  # æœ€ä½æœ¬å¾å€¼
    
    def _prepare_hartree_fock_state(self):
        """
        åˆ¶å¤‡Hartree-Fockåˆæ€
        """
        # å‰Nä¸ªå æ®æ€ä¸º1ï¼Œå…¶ä½™ä¸º0
        n_electrons = self.molecule.num_electrons
        
        state_vector = np.zeros(2**self.n_qubits)
        # ä¾‹å¦‚ï¼šå¯¹äº2ä¸ªç”µå­ï¼Œ|1100...0âŸ©
        hf_index = sum([2**i for i in range(n_electrons)])
        state_vector[hf_index] = 1.0
        
        # è½¬ä¸ºå¯†åº¦çŸ©é˜µ
        rho = np.outer(state_vector, state_vector.conj())
        
        return rho


# ä»£ç å— #7.4.50
# æ¥æº: Line 3642

"""
é‡å­æ™ºèƒ½æ¿€æ´»åè®® - ç‰©ç†ç³»ç»Ÿæ¨¡æ‹Ÿæ¨¡æ¿
é€‚ç”¨äºï¼šé‡å­å¤šä½“ç³»ç»Ÿã€å‡èšæ€ç‰©ç†ã€åœºè®ºæ¨¡æ‹Ÿç­‰
"""

class QuantumPhysicsSimulator:
    """
    é‡å­ç‰©ç†ç³»ç»Ÿæ¨¡æ‹Ÿå™¨
    """
    
    def __init__(self, system_type, lattice_size):
        self.system_type = system_type
        self.lattice_size = lattice_size
        
        # æ„é€ ç³»ç»Ÿå“ˆå¯†é¡¿é‡
        if system_type == 'Heisenberg':
            self.H = self._build_heisenberg_hamiltonian()
        elif system_type == 'Hubbard':
            self.H = self._build_hubbard_hamiltonian()
        elif system_type == 'Ising':
            self.H = self._build_ising_hamiltonian()
        else:
            raise ValueError(f"æœªçŸ¥ç³»ç»Ÿç±»å‹: {system_type}")
        
        print(f"ç‰©ç†ç³»ç»Ÿ: {system_type}")
        print(f"æ™¶æ ¼å°ºå¯¸: {lattice_size}")
        print(f"Hilbertç©ºé—´ç»´åº¦: {self.H.shape[0]}")
    
    def simulate_dynamics(self, initial_state, total_time, dt):
        """
        æ¨¡æ‹Ÿé‡å­åŠ¨åŠ›å­¦
        """
        print("\n" + "="*60)
        print("âš›ï¸ é‡å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿ")
        print("="*60)
        
        n_steps = int(total_time / dt)
        
        # Trotteråˆ†è§£
        print(f"\nä½¿ç”¨Trotteråˆ†è§£ (æ­¥æ•°: {n_steps}, dt={dt})")
        
        state = initial_state.copy()
        trajectory = [state.copy()]
        
        observables = {
            'energy': [],
            'magnetization': [],
            'entanglement': []
        }
        
        for step in range(n_steps):
            # Trotterizedæ¼”åŒ–
            state = self._trotter_step(state, dt)
            
            # è®°å½•å¯è§‚æµ‹é‡
            if step % 10 == 0:
                trajectory.append(state.copy())
                
                E = self._measure_energy(state)
                M = self._measure_magnetization(state)
                S = self._measure_entanglement_entropy(state)
                
                observables['energy'].append(E)
                observables['magnetization'].append(M)
                observables['entanglement'].append(S)
                
                if step % 50 == 0:
                    print(f"  t={step*dt:.2f}: E={E:.4f}, M={M:.4f}, S={S:.4f}")
        
        # åˆ†æç»“æœ
        results = self._analyze_dynamics(trajectory, observables, total_time)
        
        return results
    
    def find_phase_transition(self, param_name, param_range):
        """
        å¯»æ‰¾ç›¸å˜ç‚¹
        """
        print("\n" + "="*60)
        print("ğŸŒ¡ï¸ ç›¸å˜ç‚¹æœç´¢")
        print("="*60)
        
        print(f"\næ‰«æå‚æ•°: {param_name}")
        print(f"èŒƒå›´: {param_range[0]:.2f} - {param_range[1]:.2f}")
        
        param_values = np.linspace(param_range[0], param_range[1], 50)
        
        order_parameters = []
        susceptibilities = []
        
        for param_val in param_values:
            # æ›´æ–°å“ˆå¯†é¡¿é‡
            H_param = self._update_hamiltonian_parameter(param_name, param_val)
            
            # æ±‚è§£åŸºæ€
            ground_state = self._find_ground_state(H_param)
            
            # è®¡ç®—åºå‚é‡
            order_param = self._compute_order_parameter(ground_state)
            order_parameters.append(order_param)
            
            # è®¡ç®—ç£åŒ–ç‡
            chi = self._compute_susceptibility(ground_state, H_param)
            susceptibilities.append(chi)
        
        # è¯†åˆ«ä¸´ç•Œç‚¹ï¼ˆç£åŒ–ç‡å³°å€¼ï¼‰
        critical_idx = np.argmax(susceptibilities)
        critical_value = param_values[critical_idx]
        
        print(f"\nâœ“ ä¸´ç•Œç‚¹: {param_name} = {critical_value:.4f}")
        print(f"  åºå‚é‡: {order_parameters[critical_idx]:.4f}")
        print(f"  ç£åŒ–ç‡: {susceptibilities[critical_idx]:.4f}")
        
        return {
            'param_values': param_values,
            'order_parameters': order_parameters,
            'susceptibilities': susceptibilities,
            'critical_point': critical_value
        }
    
    def compute_correlation_functions(self, state):
        """
        è®¡ç®—å…³è”å‡½æ•°
        """
        print("\nè®¡ç®—ç©ºé—´å…³è”å‡½æ•°...")
        
        correlations = {}
        
        # 1. è‡ªæ—‹-è‡ªæ—‹å…³è”
        spin_corr = np.zeros((self.lattice_size, self.lattice_size))
        for i in range(self.lattice_size):
            for j in range(self.lattice_size):
                spin_corr[i, j] = self._measure_spin_correlation(state, i, j)
        
        correlations['spin'] = spin_corr
        
        # 2. å¯†åº¦-å¯†åº¦å…³è”
        density_corr = np.zeros((self.lattice_size, self.lattice_size))
        for i in range(self.lattice_size):
            for j in range(self.lattice_size):
                density_corr[i, j] = self._measure_density_correlation(state, i, j)
        
        correlations['density'] = density_corr
        
        # 3. å…³è”é•¿åº¦
        correlation_length = self._extract_correlation_length(spin_corr)
        print(f"  å…³è”é•¿åº¦: {correlation_length:.2f} æ™¶æ ¼å¸¸æ•°")
        
        return correlations
    
    def _trotter_step(self, state, dt):
        """
        Trotteråˆ†è§£å•æ­¥æ¼”åŒ–
        """
        # å°†å“ˆå¯†é¡¿é‡åˆ†è§£ä¸ºå¯äº¤æ¢éƒ¨åˆ†
        # H = H1 + H2 + ... (ä¾‹å¦‚ï¼šå•ä½“é¡¹ + è¿‘é‚»ç›¸äº’ä½œç”¨)
        
        # äºŒé˜¶Trotteråˆ†è§£ï¼š
        # exp(-iHt) â‰ˆ exp(-iH1*dt/2) exp(-iH2*dt) exp(-iH1*dt/2)
        
        H_parts = self._decompose_hamiltonian()
        
        # å‰å‘æ¼”åŒ–
        evolved_state = state.copy()
        for i, H_part in enumerate(H_parts):
            factor = dt/2 if (i == 0 or i == len(H_parts)-1) else dt
            U = expm(-1j * H_part * factor)
            evolved_state = U @ evolved_state @ U.conj().T
        
        return evolved_state
    
    def _analyze_dynamics(self, trajectory, observables, total_time):
        """
        åˆ†æåŠ¨åŠ›å­¦æ¼”åŒ–
        """
        print("\n" + "="*60)
        print("ğŸ“Š åŠ¨åŠ›å­¦åˆ†æ")
        print("="*60)
        
        analysis = {}
        
        # 1. èƒ½é‡å®ˆæ’æ£€éªŒ
        energy_drift = np.std(observables['energy'])
        print(f"\nèƒ½é‡æ¼‚ç§»: {energy_drift:.6f}")
        analysis['energy_conserved'] = energy_drift < 1e-4
        
        # 2. çº ç¼ ç†µå¢é•¿
        S_initial = observables['entanglement'][0]
        S_final = observables['entanglement'][-1]
        print(f"çº ç¼ ç†µå¢é•¿: {S_initial:.3f} â†’ {S_final:.3f}")
        analysis['entanglement_growth'] = S_final - S_initial
        
        # 3. çƒ­åŒ–æ£€éªŒ
        thermalized = self._check_thermalization(observables)
        print(f"çƒ­åŒ–: {'æ˜¯' if thermalized else 'å¦'}")
        analysis['thermalized'] = thermalized
        
        # 4. é‡å­é€Ÿåº¦æé™
        evolution_time = len(trajectory) * total_time / len(trajectory)
        qsl_time = self._quantum_speed_limit(trajectory[0], trajectory[-1])
        print(f"é‡å­é€Ÿåº¦æé™: {qsl_time:.3f}")
        print(f"å®é™…æ¼”åŒ–æ—¶é—´: {evolution_time:.3f}")
        analysis['saturates_qsl'] = evolution_time >= qsl_time
        
        return analysis
    
    def _build_heisenberg_hamiltonian(self, J=1.0):
        """
        æ„é€ Heisenbergæ¨¡å‹å“ˆå¯†é¡¿é‡
        H = J Î£_<i,j> (Ïƒ_i^x Ïƒ_j^x + Ïƒ_i^y Ïƒ_j^y + Ïƒ_i^z Ïƒ_j^z)
        """
        N = self.lattice_size
        dim = 2**N
        H = np.zeros((dim, dim), dtype=complex)
        
        # PauliçŸ©é˜µ
        sigma_x = np.array([[0, 1], [1, 0]])
        sigma_y = np.array([[0, -1j], [1j, 0]])
        sigma_z = np.array([[1, 0], [0, -1]])
        
        # è¿‘é‚»ç›¸äº’ä½œç”¨
        for i in range(N-1):
            # X-Xé¡¹
            XX = self._kron_list([np.eye(2)]*i + [sigma_x, sigma_x] + [np.eye(2)]*(N-i-2))
            H += J * XX
            
            # Y-Yé¡¹
            YY = self._kron_list([np.eye(2)]*i + [sigma_y, sigma_y] + [np.eye(2)]*(N-i-2))
            H += J * YY
            
            # Z-Zé¡¹
            ZZ = self._kron_list([np.eye(2)]*i + [sigma_z, sigma_z] + [np.eye(2)]*(N-i-2))
            H += J * ZZ
        
        return H
    
    def _quantum_speed_limit(self, initial_state, final_state):
        """
        è®¡ç®—é‡å­é€Ÿåº¦æé™ï¼ˆMandelstam-Tammç•Œï¼‰
        """
        # Ï„_QSL = (â„/Î”E) * arccos(F)
        # å…¶ä¸­ F = fidelity, Î”E = èƒ½é‡ä¸ç¡®å®šåº¦
        
        F = fidelity(initial_state, final_state)
        
        # èƒ½é‡ä¸ç¡®å®šåº¦
        E = np.real(np.trace(self.H @ initial_state))
        E2 = np.real(np.trace(self.H @ self.H @ initial_state))
        Delta_E = np.sqrt(E2 - E**2)
        
        if Delta_E < 1e-10:
            return np.inf
        
        tau_QSL = np.arccos(np.sqrt(F)) / Delta_E
        
        return tau_QSL

